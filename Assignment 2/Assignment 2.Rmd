---
title: "Assignment 2"
author: "Hanish Bhogadi"
date: "2/20/2022"
output:
  pdf_document: default
  word_document: default
---
```{r}
setwd("C:/Users/Hanish Bhogadi/Documents/Assignment 2")
```

```{r}
#Calling libraries

library('caret')
library('ISLR')
library('dplyr')
library('class')

#Importing Data
Bank <- read.csv("C:/Users/Hanish Bhogadi/Documents/Assignment 2/UniversalBank.csv")

#MakingID and ZIP code as NULL
Bank$ID <- NULL
Bank$ZIP.Code <- NULL
summary(Bank)

Bank$Personal.Loan = as.factor(Bank$Personal.Loan)

summary(Bank)

#Normalization
Model_range_normalized <- preProcess(Bank[,-8],method = "range")
Bank_norm <- predict(Model_range_normalized,Bank)
summary(Bank_norm)
View(Bank_norm)

#Data Partition into testing and training sets
Train_index <- createDataPartition(Bank$Personal.Loan, p = 0.6, list = FALSE)
train.df = Bank_norm[Train_index,]
validation.df = Bank_norm[-Train_index,]

#Predict k value
To_Predict = data.frame(Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education = 1, Mortgage = 0, Securities.Account = 0, CD.Account = 0, Online = 1, CreditCard = 1)
print(To_Predict)
Prediction <- knn(train = train.df[,1:7,9:12], test = To_Predict_norm[,1:7,9:12], cl = train.df$Personal.Loan, k = 1)
print(Prediction)

#Question 2 - Finding best value of k
set.seed(123)
Bankcontrol <- trainControl(method = "repeatedcv", number = 3, repeats = 2)
searchGrid = expand.grid(k=1:10)

knn.model = train(Personal.Loan~., data = train.df, method = 'knn', tuneGrid = searchGrid, trControl = Bankcontrol)
knn.model

#Question 3 - Confusion matrix from using the best k
predictions <- predict(knn.model, validation.df)
confusionMatrix(predictions, validation.df$Personal.Loan)

#Question 4 - Classify the customer using the best k.
To_Predict_norm = data.frame(Age = 40, Experience = 10, Income = 84, family = 2, CCAvg = 2, Education = 1, Mortgage = 0, Securities.Account = 0, CD.Account = 0, Online = 1, CreditCard = 1)
To_Predict_norm = predict(Model_range_normalized, To_Predict)
predict(knn.model, To_Predict_norm)

#Question 5 
#New split

train_size = 0.5
Train_index = createDataPartition(Bank$Personal.Loan, p = 0.5, list = FALSE)
train.df = Bank_norm[Train_index,]

test_size = 0.2
Test_index = createDataPartition(Bank$Personal.Loan, p = 0.2, list = FALSE)
Test.df = Bank_norm[Test_index,]

valid_size = 0.3
Validation_index = createDataPartition(Bank$Personal.Loan, p = 0.3, list = FALSE)
validation.df = Bank_norm[Validation_index,]


Testknn <- knn(train = train.df[,-8], test = Test.df[,-8], cl = train.df[,8], k =1)
Validationknn <- knn(train = train.df[,-8], test = validation.df[,-8], cl = train.df[,8], k =1)
Trainknn <- knn(train = train.df[,-8], test = train.df[,-8], cl = train.df[,8], k =1)

#Confusion Matrix
confusionMatrix(Testknn, Test.df[,8])
confusionMatrix(Trainknn, train.df[,8])
confusionMatrix(Validationknn, validation.df[,8])

#From the above, comparing confusion matrix of the test set with that of the training and validation sets we #can determine that a slightly higher training set means that there is no over fitting of data and found the #better value of k.
```
